{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a8be4c",
   "metadata": {},
   "source": [
    "In this notebook we are going over the different modeling and balancing techniques used for this project. The target for the modeling will be: \n",
    "    • 'popularity_category'\n",
    "    \n",
    "The features used are:\n",
    "\n",
    "    • 'explicit'\n",
    "    • 'danceability'\n",
    "    • 'energy'\n",
    "    • 'key'\n",
    "    • 'loudness'\n",
    "    • 'mode'\n",
    "    • 'speechiness'\n",
    "    • 'acousticness'\n",
    "    • 'instrumentalness'\n",
    "    • 'liveness'\n",
    "    • 'valence'\n",
    "    • 'tempo'\n",
    "    • 'time_signature'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87952f",
   "metadata": {},
   "source": [
    "We saw in the EDA that some features had more impact than others when making a song popular, this will show us the impact the features will make through the modeling process.\n",
    "We also saw how umbalance the data was when splitting the popularity feature. These are the techniques used for balancing the data: \n",
    "\n",
    "    • Random Over Sampler: This works by randomly relecting examples form the minority class, with replacement, and adding them to the training dataset.\n",
    "    \n",
    "    • Near Miss undersampling: Near Miss looks at the class distribution and randomly eliminates sample from the larger class. If two data point from the larger class are very close to each other in the distribution it is eliminated.\n",
    "    \n",
    "    •Weight: Normally class weights give all the classes a equal importance regardless of how many samples each class has. Weights are set into place to give more weight(importance) to the minority class to balance the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796dcd27",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9097ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851e143",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d34a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_clean = pd.read_csv('./data/tracks_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c115b4",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefe9cf",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26da290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(model, \n",
    "                 X_train, y_train, X_test, y_test,\n",
    "                 verbose=True):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    results['train_accuracy'] = accuracy_score(y_train, y_pred_train)\n",
    "    results['test_accuracy'] = accuracy_score(y_test, y_pred_test)\n",
    "    results['variance'] = results['train_accuracy'] - results['test_accuracy']\n",
    "    results['test_recall'] = recall_score(y_test, y_pred_test, pos_label=1, zero_division=0)\n",
    "    results['test_precision'] = precision_score(y_test, y_pred_test, pos_label=1, zero_division=0)\n",
    "    results['test_f1'] = f1_score(y_test, y_pred_test, pos_label=1, zero_division=0)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b5fce",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0d9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(models, X_train, y_train, X_test, y_test, verbose=False):\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for name,model in models.items():\n",
    "        if verbose:\n",
    "            print('\\nRunning {} - {}'.format(name, model))\n",
    "        \n",
    "        results[name] = baseline(model, X_train, y_train, X_test, y_test, verbose=False)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Results: ', results[name])\n",
    "\n",
    "    return pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e4f21",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94bf5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Dummy': DummyClassifier(strategy='most_frequent'),\n",
    "          'Logistic Regression': LogisticRegression(solver='lbfgs'),\n",
    "          'Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "          'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "          'XGBoost': XGBClassifier(),\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc9547",
   "metadata": {},
   "source": [
    "###### Why did I chose these models?\n",
    "    When I was looking at what models to pick, I had to look at a few things. What models are best for classification? Which models are good for binary classification? Non-Linear relationships? The first thing I looked at was my EDA to see what kind of relationships my data has. Logistic Regression is one of the simpler and most used classification models so I included it to be my starting point for my classification models. Unfortunately my data was not very linear, to satify that I included the Random Forest model. Random Forest works really well for multiple feature selection, large data, and noise which made this a good choise. XGBoost is similar to Random Forest because it also uses Decision Trees, but works better for unbalanced data. KNearestNeighbors works by estimating the likelihood that a data point will become a member of one group or another based on the data points nearest to it. Since in some of the models we saw a seperation between the graphs, I thought it would be a good model to include."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa14e9",
   "metadata": {},
   "source": [
    "## Train/ Test/ Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7540fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up X and y\n",
    "X = tracks_clean.drop(columns=['popularity', 'popularity_category', 'release_date'])\n",
    "y = tracks_clean['popularity_category']\n",
    "\n",
    "#test/train/split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f3a9a",
   "metadata": {},
   "source": [
    "## Unbalanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "946c7020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train Class Distribution:\n",
      " 1    0.923916\n",
      "0    0.076084\n",
      "Name: popularity_category, dtype: float64\n",
      "\n",
      "y_test Class Distribution:\n",
      " 1    0.923915\n",
      "0    0.076085\n",
      "Name: popularity_category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Unbalanced data\n",
    "\n",
    "print('\\ny_train Class Distribution:\\n', y_train.value_counts(normalize=True))\n",
    "print('\\ny_test Class Distribution:\\n', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef8d765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Dummy - DummyClassifier(strategy='most_frequent')\n",
      "Results:  {'train_accuracy': 0.9239163541311513, 'test_accuracy': 0.923914599968633, 'variance': 1.7541625182415643e-06, 'test_recall': 1.0, 'test_precision': 0.923914599968633, 'test_f1': 0.9604528184189635}\n",
      "\n",
      "Running Logistic Regression - LogisticRegression()\n",
      "Results:  {'train_accuracy': 0.9239163541311513, 'test_accuracy': 0.923914599968633, 'variance': 1.7541625182415643e-06, 'test_recall': 1.0, 'test_precision': 0.923914599968633, 'test_f1': 0.9604528184189635}\n",
      "\n",
      "Running Nearest Neighbors - KNeighborsClassifier()\n",
      "Results:  {'train_accuracy': 0.9296101829753382, 'test_accuracy': 0.9188276929581114, 'variance': 0.010782490017226753, 'test_recall': 0.9894828515126243, 'test_precision': 0.9275045486935045, 'test_f1': 0.9574917868875874}\n",
      "\n",
      "Running Random Forest - RandomForestClassifier()\n",
      "Results:  {'train_accuracy': 0.9979884077736106, 'test_accuracy': 0.9459874122917675, 'variance': 0.052000995481843115, 'test_recall': 0.9902135165654314, 'test_precision': 0.9531478666117276, 'test_f1': 0.9713272157969992}\n",
      "\n",
      "Running XGBoost - XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "Results:  {'train_accuracy': 0.9470803500397772, 'test_accuracy': 0.9432189347498483, 'variance': 0.0038614152899288934, 'test_recall': 0.9888850346512366, 'test_precision': 0.9515581501051077, 'test_f1': 0.9698625774065242}\n"
     ]
    }
   ],
   "source": [
    "unbalanced_model_results = run_models(models,\n",
    "                                  X_train, y_train,\n",
    "                                  X_test, y_test,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e9ec7",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "945ab1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersamlping data using NearMiss\n",
    "nr = NearMiss() \n",
    "\n",
    "X_train_near, y_train_near= nr.fit_resample(X_train, y_train) \n",
    "\n",
    "#https://analyticsindiamag.com/using-near-miss-algorithm-for-imbalanced-datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b510887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train Class Distribution:\n",
      " 0    0.5\n",
      "1    0.5\n",
      "Name: popularity_category, dtype: float64\n",
      "\n",
      "y_test Class Distribution:\n",
      " 1    0.923915\n",
      "0    0.076085\n",
      "Name: popularity_category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('\\ny_train Class Distribution:\\n', y_train_near.value_counts(normalize=True))\n",
    "print('\\ny_test Class Distribution:\\n', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67527f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Dummy - DummyClassifier(strategy='most_frequent')\n",
      "Results:  {'train_accuracy': 0.5, 'test_accuracy': 0.07608540003136699, 'variance': 0.423914599968633, 'test_recall': 0.0, 'test_precision': 0.0, 'test_f1': 0.0}\n",
      "\n",
      "Running Logistic Regression - LogisticRegression()\n",
      "Results:  {'train_accuracy': 0.5, 'test_accuracy': 0.07608540003136699, 'variance': 0.423914599968633, 'test_recall': 0.0, 'test_precision': 0.0, 'test_f1': 0.0}\n",
      "\n",
      "Running Nearest Neighbors - KNeighborsClassifier()\n",
      "Results:  {'train_accuracy': 0.774773698204523, 'test_accuracy': 0.29907058253949853, 'variance': 0.4757031156650245, 'test_recall': 0.2697999158628121, 'test_precision': 0.9046051817574423, 'test_f1': 0.4156358013461888}\n",
      "\n",
      "Running Random Forest - RandomForestClassifier()\n",
      "Results:  {'train_accuracy': 0.9919786096256684, 'test_accuracy': 0.5295906608205877, 'variance': 0.4623879488050807, 'test_recall': 0.5018414235421756, 'test_precision': 0.9785709145858819, 'test_f1': 0.663446808925836}\n",
      "\n",
      "Running XGBoost - XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "Results:  {'train_accuracy': 0.897828100259911, 'test_accuracy': 0.5294133691553415, 'variance': 0.36841473110456946, 'test_recall': 0.5027713608821119, 'test_precision': 0.9764775024009862, 'test_f1': 0.6637759675722026}\n"
     ]
    }
   ],
   "source": [
    "undersampled_model_results = run_models(models,\n",
    "                                        X_train_near, y_train_near,\n",
    "                                        X_test, y_test,\n",
    "                                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe52b9",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54c1845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling with RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "X_train_over, y_train_over = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ec14a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train Class Distribution:\n",
      " 1    0.5\n",
      "0    0.5\n",
      "Name: popularity_category, dtype: float64\n",
      "\n",
      "y_test Class Distribution:\n",
      " 1    0.923915\n",
      "0    0.076085\n",
      "Name: popularity_category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('\\ny_train Class Distribution:\\n', y_train_over.value_counts(normalize=True))\n",
    "print('\\ny_test Class Distribution:\\n', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1322394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Dummy - DummyClassifier(strategy='most_frequent')\n",
      "Results:  {'train_accuracy': 0.5, 'test_accuracy': 0.07608540003136699, 'variance': 0.423914599968633, 'test_recall': 0.0, 'test_precision': 0.0, 'test_f1': 0.0}\n",
      "\n",
      "Running Logistic Regression - LogisticRegression()\n",
      "Results:  {'train_accuracy': 0.5190527385313314, 'test_accuracy': 0.8410921166579157, 'variance': -0.32203937812658434, 'test_recall': 0.8989394286051678, 'test_precision': 0.9268630479944602, 'test_f1': 0.9126877079399335}\n",
      "\n",
      "Running Nearest Neighbors - KNeighborsClassifier()\n",
      "Results:  {'train_accuracy': 0.9397739601502668, 'test_accuracy': 0.7977988557868682, 'variance': 0.14197510436339866, 'test_recall': 0.8323898651590858, 'test_precision': 0.9420092544643602, 'test_f1': 0.88381350918231}\n",
      "\n",
      "Running Random Forest - RandomForestClassifier()\n",
      "Results:  {'train_accuracy': 0.9985275919670732, 'test_accuracy': 0.9446099924310096, 'variance': 0.053917599536063565, 'test_recall': 0.9832611278811452, 'test_precision': 0.9579019269485188, 'test_f1': 0.9704158821151389}\n",
      "\n",
      "Running XGBoost - XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "Results:  {'train_accuracy': 0.8599047424577528, 'test_accuracy': 0.8570688232606665, 'variance': 0.0028359191970863673, 'test_recall': 0.8623914150546522, 'test_precision': 0.9805646000469941, 'test_f1': 0.9176892840173253}\n"
     ]
    }
   ],
   "source": [
    "oversampled_model_results = run_models(models,\n",
    "                                        X_train_over, y_train_over,\n",
    "                                        X_test, y_test,\n",
    "                                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efab1a9",
   "metadata": {},
   "source": [
    "## Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60669a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_weighted = {'Logistic Regression': LogisticRegression(solver='lbfgs', class_weight='balanced'),\n",
    "          'Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
    "          'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced'),\n",
    "          'XGBoost': XGBClassifier(scale_pos_weight=5),\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a07e0484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train Class Distribution:\n",
      " 1    0.5\n",
      "0    0.5\n",
      "Name: popularity_category, dtype: float64\n",
      "\n",
      "y_test Class Distribution:\n",
      " 1    0.923915\n",
      "0    0.076085\n",
      "Name: popularity_category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('\\ny_train Class Distribution:\\n', y_train_over.value_counts(normalize=True))\n",
    "print('\\ny_test Class Distribution:\\n', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f53d3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Logistic Regression - LogisticRegression(class_weight='balanced')\n",
      "Results:  {'train_accuracy': 0.8426366632571883, 'test_accuracy': 0.8428036631185604, 'variance': -0.00016699986137203027, 'test_recall': 0.9009764342069332, 'test_precision': 0.9268403790087464, 'test_f1': 0.9137254168148051}\n",
      "\n",
      "Running Nearest Neighbors - KNeighborsClassifier(weights='distance')\n",
      "Results:  {'train_accuracy': 0.9979906807591772, 'test_accuracy': 0.9197755214761577, 'variance': 0.07821515928301948, 'test_recall': 0.9832611278811452, 'test_precision': 0.9334580513165455, 'test_f1': 0.9577125604298834}\n",
      "\n",
      "Running Random Forest - RandomForestClassifier(class_weight='balanced')\n",
      "Results:  {'train_accuracy': 0.997381520627344, 'test_accuracy': 0.9441599443576928, 'variance': 0.05322157626965118, 'test_recall': 0.9902947015712988, 'test_precision': 0.9512661996994016, 'test_f1': 0.970388182755067}\n",
      "\n",
      "Running XGBoost - XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...)\n",
      "Results:  {'train_accuracy': 0.938824866462098, 'test_accuracy': 0.9360318033971811, 'variance': 0.0027930630649168897, 'test_recall': 0.9982286907810736, 'test_precision': 0.9366940454589526, 'test_f1': 0.9664829020283187}\n"
     ]
    }
   ],
   "source": [
    "weighted_model_results = run_models(models_weighted,\n",
    "                                        X_train, y_train,\n",
    "                                        X_test, y_test,\n",
    "                                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687f69d",
   "metadata": {},
   "source": [
    "# Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1963a7",
   "metadata": {},
   "source": [
    "## Unbalanced Modeling Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65a798cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>variance</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.997988</td>\n",
       "      <td>0.945987</td>\n",
       "      <td>0.052001</td>\n",
       "      <td>0.990214</td>\n",
       "      <td>0.953148</td>\n",
       "      <td>0.971327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.947080</td>\n",
       "      <td>0.943219</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.988885</td>\n",
       "      <td>0.951558</td>\n",
       "      <td>0.969863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.923916</td>\n",
       "      <td>0.923915</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923915</td>\n",
       "      <td>0.960453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.923916</td>\n",
       "      <td>0.923915</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923915</td>\n",
       "      <td>0.960453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.929610</td>\n",
       "      <td>0.918828</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>0.989483</td>\n",
       "      <td>0.927505</td>\n",
       "      <td>0.957492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_accuracy  test_accuracy  variance  test_recall  \\\n",
       "Random Forest              0.997988       0.945987  0.052001     0.990214   \n",
       "XGBoost                    0.947080       0.943219  0.003861     0.988885   \n",
       "Dummy                      0.923916       0.923915  0.000002     1.000000   \n",
       "Logistic Regression        0.923916       0.923915  0.000002     1.000000   \n",
       "Nearest Neighbors          0.929610       0.918828  0.010782     0.989483   \n",
       "\n",
       "                     test_precision   test_f1  \n",
       "Random Forest              0.953148  0.971327  \n",
       "XGBoost                    0.951558  0.969863  \n",
       "Dummy                      0.923915  0.960453  \n",
       "Logistic Regression        0.923915  0.960453  \n",
       "Nearest Neighbors          0.927505  0.957492  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbalanced_model_results.sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7d7ca",
   "metadata": {},
   "source": [
    "## Undersampling Modeling Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "369c2dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>variance</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.991979</td>\n",
       "      <td>0.529591</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.501841</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.663447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.897828</td>\n",
       "      <td>0.529413</td>\n",
       "      <td>0.368415</td>\n",
       "      <td>0.502771</td>\n",
       "      <td>0.976478</td>\n",
       "      <td>0.663776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.774774</td>\n",
       "      <td>0.299071</td>\n",
       "      <td>0.475703</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.904605</td>\n",
       "      <td>0.415636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.076085</td>\n",
       "      <td>0.423915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.076085</td>\n",
       "      <td>0.423915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_accuracy  test_accuracy  variance  test_recall  \\\n",
       "Random Forest              0.991979       0.529591  0.462388     0.501841   \n",
       "XGBoost                    0.897828       0.529413  0.368415     0.502771   \n",
       "Nearest Neighbors          0.774774       0.299071  0.475703     0.269800   \n",
       "Dummy                      0.500000       0.076085  0.423915     0.000000   \n",
       "Logistic Regression        0.500000       0.076085  0.423915     0.000000   \n",
       "\n",
       "                     test_precision   test_f1  \n",
       "Random Forest              0.978571  0.663447  \n",
       "XGBoost                    0.976478  0.663776  \n",
       "Nearest Neighbors          0.904605  0.415636  \n",
       "Dummy                      0.000000  0.000000  \n",
       "Logistic Regression        0.000000  0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_model_results.sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b895fe",
   "metadata": {},
   "source": [
    "## Oversampling Modeling Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d05e358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>variance</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.998528</td>\n",
       "      <td>0.944610</td>\n",
       "      <td>0.053918</td>\n",
       "      <td>0.983261</td>\n",
       "      <td>0.957902</td>\n",
       "      <td>0.970416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.859905</td>\n",
       "      <td>0.857069</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.862391</td>\n",
       "      <td>0.980565</td>\n",
       "      <td>0.917689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.519053</td>\n",
       "      <td>0.841092</td>\n",
       "      <td>-0.322039</td>\n",
       "      <td>0.898939</td>\n",
       "      <td>0.926863</td>\n",
       "      <td>0.912688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.939774</td>\n",
       "      <td>0.797799</td>\n",
       "      <td>0.141975</td>\n",
       "      <td>0.832390</td>\n",
       "      <td>0.942009</td>\n",
       "      <td>0.883814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.076085</td>\n",
       "      <td>0.423915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_accuracy  test_accuracy  variance  test_recall  \\\n",
       "Random Forest              0.998528       0.944610  0.053918     0.983261   \n",
       "XGBoost                    0.859905       0.857069  0.002836     0.862391   \n",
       "Logistic Regression        0.519053       0.841092 -0.322039     0.898939   \n",
       "Nearest Neighbors          0.939774       0.797799  0.141975     0.832390   \n",
       "Dummy                      0.500000       0.076085  0.423915     0.000000   \n",
       "\n",
       "                     test_precision   test_f1  \n",
       "Random Forest              0.957902  0.970416  \n",
       "XGBoost                    0.980565  0.917689  \n",
       "Logistic Regression        0.926863  0.912688  \n",
       "Nearest Neighbors          0.942009  0.883814  \n",
       "Dummy                      0.000000  0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_model_results.sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58375d53",
   "metadata": {},
   "source": [
    "## Weighted Modeling Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba9af2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>variance</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.997382</td>\n",
       "      <td>0.944160</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>0.990295</td>\n",
       "      <td>0.951266</td>\n",
       "      <td>0.970388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.938825</td>\n",
       "      <td>0.936032</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.936694</td>\n",
       "      <td>0.966483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.997991</td>\n",
       "      <td>0.919776</td>\n",
       "      <td>0.078215</td>\n",
       "      <td>0.983261</td>\n",
       "      <td>0.933458</td>\n",
       "      <td>0.957713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.842637</td>\n",
       "      <td>0.842804</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.900976</td>\n",
       "      <td>0.926840</td>\n",
       "      <td>0.913725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_accuracy  test_accuracy  variance  test_recall  \\\n",
       "Random Forest              0.997382       0.944160  0.053222     0.990295   \n",
       "XGBoost                    0.938825       0.936032  0.002793     0.998229   \n",
       "Nearest Neighbors          0.997991       0.919776  0.078215     0.983261   \n",
       "Logistic Regression        0.842637       0.842804 -0.000167     0.900976   \n",
       "\n",
       "                     test_precision   test_f1  \n",
       "Random Forest              0.951266  0.970388  \n",
       "XGBoost                    0.936694  0.966483  \n",
       "Nearest Neighbors          0.933458  0.957713  \n",
       "Logistic Regression        0.926840  0.913725  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_model_results.sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68db83",
   "metadata": {},
   "source": [
    "### Modeling Summary:\n",
    "For this project we will be looking more at accuracy, because we are looking at how well the model can predict popularity of a song.\n",
    "\n",
    "    Unbalanced modeling: Suprisingly the unbalanced models did not perform that bad. This could be because the data is very ubalanced and could be very overfit. The best performing model was Random Forest with a training score of 0.997988 and a test score of 0.945987.\n",
    "    \n",
    "    Undersampling modeling: Undersampling performed the worst out of all the different balancing techniques used. The results were extremly over-fitt showing high train score and low test scores, and also has a very high variance score.\n",
    "    \n",
    "    Oversampling modeling: Oversampling had the best results. The results had high training and test score with very low variance. The best model was Random Forest with a training score of 0.998528 and a test score of 0.944610. We will proceed with this model for model tunning. \n",
    "    \n",
    "    Weighted modeling: Weighted modeling also performed very well. Random Forest was also the best performing and had very similar scores to the oversampling. This is the second best data balancing technique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
